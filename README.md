Esta es una página destinada a ilustrar el uso de GitHub para mostrar ejemplos imoortantes de Graph machine learning.
Este maerial hará parte del Libro Ciencia de redes.

# Ejemplo  1  (Uso de node2vec)


we show an example using a particular embedding algorithm known as Node to Vector (Node2Vec).

![](./Imagenes/Figure1.PNG)

In the preceding code, we have done the following:
1. We generated a barbell graph (described in the previous chapter).
2. The Node2Vec embedding algorithm is then used in order to map each node of the
graph in a vector of two dimensions.
3. Finally, the two-dimensional vectors generated by the embedding algorithm,
representing the nodes of the original graph, are plotted.

The result is shown in the following figure:

![](./Imagenes/Figure1-2.PNG)

it is easy to see that nodes that have a similar structure are close to each
other and are distant from nodes that have dissimilar structures. It is also interesting
to observe how good Node2Vec is at discriminating group 1 from group 3. Since the
algorithm uses neighboring information of each node to generate the representation, the
clear discrimination of those two groups is possible.

Another example on the same graph can be performed using the Edge to Vector
(Edge2Vec) algorithm in order to generate a mapping for the edges for the same graph, G:


![](./Imagenes/Figure1-3.PNG)



In the preceding code, we have done the following:
1. We generated a barbell graph (described in the previous chapter).
2. The HadamardEmbedder embedding algorithm is applied to the result of the
Node2Vec algorithm (keyed_vectors=model.wv) used in order to map each
edge of the graph in a vector of two dimensions.
3. Finally, the two-dimensional vectors generated by the embedding algorithm,
representing the nodes of the original graph, are plotted.
The results are shown in the following figure:

![](./Imagenes/Figure1-4.PNG)

From the figure, it is easy to see that the edge embedding algorithm clearly
identifies similar edges. As expected, edges belonging to groups 1, 2, and 3 are clustered in
well-defined and well-grouped regions. Moreover, the (6,7) and (10,11) edges, belonging
to groups 4 and 5, respectively, are well clustered in specific groups.



Finally, we will provide an example of a Graph to Vector (Grap2Vec) embedding
algorithm. This algorithm maps a single graph in a vector. As for another example, we
will discuss this algorithm in more detail in the next chapter. In the following code block,
we provide a Python example showing how to use the Graph2Vec algorithm in order to
generate the embedding representation on a set of graphs:



![](./Imagenes/Figure1-5.PNG)




In this example, the following has been done:
1. 20 Watts-Strogatz graphs (described in the previous chapter) have been generated
with random parameters.
2. We have then executed the graph embedding algorithm in order to generate a
two-dimensional vector representation of each graph.
3. Finally, the generated vectors are plotted in their Euclidean space.
The results of this example are the following:




![](./Imagenes/Figure1-6.PNG)





graphs with a large Euclidean distance, such as graph 12
and graph 8, have a different structure. The former is generated with the nx.watts_
strogatz_graph(20,20,0.2857) parameter and the latter with the nx.watts_
strogatz_graph(13,6,0.8621) parameter. In contrast, a graph with a low
Euclidean distance, such as graph 14 and graph 8, has a similar structure. Graph 14 is
generated with the nx.watts_strogatz_graph(9,9,0.5091) command, while
graph 4 is generated with nx.watts_strogatz_graph(10,5,0.5659).


### Ejemplo 2 Un sistema de recomendación de películas


One of the most popular applications of GNNs is RecSys. If you think about the foundation of Word2Vec
(and, thus, DeepWalk and Node2Vec), the goal is to produce vectors with the ability to measure their
similarity. Encode movies instead of words, and you can suddenly ask for movies that are the most
similar to a given input title. It sounds a lot like a RecSys, right?
But how to encode movies? We want to create (biased) random walks of movies, but this requires a
graph dataset where similar movies are connected to each other. This is not easy to find.
Another approach is to look at user ratings. There are different techniques to build a graph based on
ratings: bipartite graphs, edges based on pointwise mutual information, and so on. In this section, we’ll
implement a simple and intuitive approach: movies that are liked by the same users are connected.
We’ll then use this graph to learn movie embeddings using Node2Vec:

1. First, let’s download a dataset. MovieLens [2] is a popular choice, with a small version of
the latest dataset (09/2018) comprising 100,836 ratings, 9,742 movies, and 610 users. We can
download it with the following Python code:

![](./Imagenes/Ejemplo2/Ej2Figure-1.PNG)

2. We are interested in two files: ratings.csv and movies.csv. The first one stores all the
ratings made by users, and the second one allows us to translate movie identifiers into titles.
3. Let’s see what they look like by importing them with pandas using pd.read_csv():



![](./Imagenes/Ejemplo2/Ej2Figure-2.PNG)

![](./Imagenes/Ejemplo2/Ej2Figure-3.PNG)

4. This gives us the following output:

![](./Imagenes/Ejemplo2/Ej2Figure-4.PNG)


5. Let’s import movies.csv now:

   ![](./Imagenes/Ejemplo2/Ej2Figure-5.PNG)


6.  This dataset gives us this output:

   ![](./Imagenes/Ejemplo2/Ej2Figure-6.PNG)


7.  Here, we want to see movies that have been liked by the same users. This means that ratings
such as 1, 2, and 3 are not very relevant. We can discard those and only keep scores of 4 and 5:

![](./Imagenes/Ejemplo2/Ej2Figure-7.PNG)


8. This gives us the following output:

    ![](./Imagenes/Ejemplo2/Ej2Figure-8.PNG)

9. We now have 48,580 ratings made by 610 users. The next step is to count every time that two
movies are liked by the same user. We will repeat this process for every user in the dataset.



10. To simplify things, we will use a defaultdict data structure, which automatically creates
missing entries instead of raising an error. We’ll use this structure to count movies that are
liked together:

![](./Imagenes/Ejemplo2/Ej2Figure-10.PNG)

11. We loop through the entire list of users in our dataset:

![](./Imagenes/Ejemplo2/Ej2Figure-11.PNG)

12. We retrieve the list of movies that have been liked by the current user:

![](./Imagenes/Ejemplo2/Ej2Figure-12.PNG)

13. We increment a counter specific to a pair of movies every time they are seen together in the
same list:

![](./Imagenes/Ejemplo2/Ej2Figure-13.PNG)

14. The pairs object now stores the number of times two movies have been liked by the same
user. We can use this information to build the edges of our graph as follows.

15. We create a graph using the networkx library:

![](./Imagenes/Ejemplo2/Ej2Figure-15.PNG)

16. For each pair of movies in our pairs structure, we unpack the two movies and their
corresponding score:

![](./Imagenes/Ejemplo2/Ej2Figure-16.PNG)

17. If this score is higher than 10, we add a weighted link to the graph to connect both movies
based on this score. We don’t consider scores lower than 10 because that would create a large
graph in which connections were less meaningful:

![](./Imagenes/Ejemplo2/Ej2Figure-17.PNG)

18. The graph we created has 410 nodes (movies) and 14,936 edges. We can now train Node2Vec
on it to learn the node embeddings!
